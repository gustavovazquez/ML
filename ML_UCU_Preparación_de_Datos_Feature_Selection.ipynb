{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gustavovazquez/ML/blob/main/ML_UCU_Preparaci%C3%B3n_de_Datos_Feature_Selection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_L_BKcnTCmLV"
      },
      "source": [
        "# Usando ScikitLearn\n",
        "## Preparación de Datos - Feature Selection\n",
        "\n",
        "Autor: Gustavo Vazquez (material propio y de Jason Brownlee - Data Preparation for Machine Learning - Data Cleaning, Feature Selection, and Data-machine learning mastery)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIMPyaGJmplw"
      },
      "source": [
        "# Preparación de datos - contaminación de datos de testeo en entrenamiento (data leakage)\n",
        "\n",
        "La preparación de datos es el proceso de transformar los datos originales a una forma que sea apropiada para el modelado. El data leakage (o contaminación) se produce cuando se utiliza información externa al conjunto de datos de entrenamiento para crear el modelo.\n",
        "\n",
        "Un enfoque errado al momento de preparar los datos es aplicar las transformaciones en todo el dataset. Cuando  esto sucede, se filtra información relativa al conjunto de datos de testeo en el de entrenamiento, violando uno de los principios fundamentales del desarrollo de modelos. Esto puede dar como resultado una estimación incorrecta del rendimiento del modelo al hacer predicciones sobre esos supuestos nuevos datos.\n",
        "Se requiere una aplicación cuidadosa de las técnicas de preparación de datos para evitar el data leakage, y esto varía según el esquema de evaluación del modelo utilizado.\n",
        "\n",
        "#Efecto de aplicar las transformaciones en todo el dataset\n",
        "Como se indicó anteriormente, un error común es aplicar las transformaciones al dataset completo. Luego el data set es dividido en conjuntos de entrenamiento y testeo (o con un esquema k-fold cross-validation). Sin embargo este enfoque es peligroso e incorrecto. Esta no es una forma directa de contaminación del proceso de entrenamiento, ya que no se usan los valores explícitos de testeo al momento de aprender el modelo sino que se filtra información \"extra\" del conjunto de testeo.\n",
        "\n",
        "Por ejemplo, consideremos el caso donde buscamos normalizar los datos. Cuando normalizamos las variables de entrada (consideremos una normalización escalando los valores entre el rango [0,1]), esto requiere que calculemos los valores máximos y mínimos para cada variable. Luego el dataset se separa en conjuntos de entrenamiento y testeo, pero los ejemplos en el conjunto de entrenamiento conocen una característica el conjunto de testeo, que es la escala que tiene.\n",
        "\n",
        "La misma situación ocurre con prácticamente todas las técnicas de preparación de los datos. Por ejemplo la estandarización estima la media y el desvío estándar, por lo que contar con esa información de los datos de testeo en el entrenamiento es una situación no deseable (pues son datos que en definitiva no deberíamos conocer). Algo similar ocurre en modelos que imputan valores faltantes usando erróneamente todo el dataset.\n",
        "\n",
        "La forma correcta debe ser:\n",
        "\n",
        "1.\tDividir Datos en entrenamiento y testeo (o el mecanismo utilizado)\n",
        "2.\tAjustar la preparación de los datos en el dataset de entrenamiento\n",
        "3.\tAplicar esa preparación en los conjuntos de entrenamiento y testeo\n",
        "4.\tEvaluar los modelos\n",
        "\n",
        "## Forma errónea usando conjuntos de entrenamiento y testeo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSv-GhWEt5DW",
        "outputId": "e2a69ec2-198c-4611-b106-b515e0d2ef20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 83.03\n"
          ]
        }
      ],
      "source": [
        "# enfoque incorrecto de normalizar los datos antes de separar los datos\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "# construimos el dataset en forma sintética\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5,\n",
        "random_state=12)\n",
        "# escala los datos (MinMaxScaler por defecto transforma todo entre 0 y 1)\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "# split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=23)\n",
        "# definirmos el modelo logístico y entrenamos\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "# evaluación\n",
        "yhat = model.predict(X_test)\n",
        "# evaluamos accuracy\n",
        "accuracy = accuracy_score(y_test, yhat)\n",
        "print(f\"Accuracy: {accuracy*100:5.2f}\" )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MzkPwLzuHce"
      },
      "source": [
        "## Evaluación con preparación de datos correcta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "il1B56rquOba",
        "outputId": "a01419e2-0663-43e9-9987-e3becdcef2d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 82.727\n"
          ]
        }
      ],
      "source": [
        "# enfoque correcto de normalizar los datos antes de separar los datos\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "# construimos el dataset en forma sintética\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5,\n",
        "random_state=12)\n",
        "# split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=23)\n",
        "# escala los datos (MinMaxScaler por defecto transforma todo entre 0 y 1)\n",
        "scaler = MinMaxScaler()\n",
        "# generamos el \"modelo\" para escalar los datos (tomando como referencia los datos de X_train)\n",
        "scaler.fit(X_train)\n",
        "# aplicamos al set de entrenamiento\n",
        "X_train = scaler.transform(X_train)\n",
        "\n",
        "# definirmos el modelo logístico y entrenamos\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# aplicamos al set de test\n",
        "X_test = scaler.transform(X_test)\n",
        "# predecimos\n",
        "yhat = model.predict(X_test)\n",
        "# evaluamos accuracy\n",
        "accuracy = accuracy_score(y_test, yhat)\n",
        "print('Accuracy: %.3f' % (accuracy*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uClVWlKu5jH"
      },
      "source": [
        "## Forma errónea utilizando k-fold cross validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1v_wagakjHtl",
        "outputId": "5d03e385-32cd-45f4-eb5a-02a9fb1456b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 83.100 (3.448)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.8 , 0.85, 0.86, 0.81, 0.84, 0.82, 0.81, 0.79, 0.81, 0.91, 0.86,\n",
              "       0.74, 0.82, 0.84, 0.85, 0.84, 0.84, 0.82, 0.81, 0.88, 0.91, 0.83,\n",
              "       0.83, 0.79, 0.82, 0.87, 0.81, 0.85, 0.81, 0.81])"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ],
      "source": [
        "# enfoque incorrecto de normalizar los datos antes de separar los datos\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# construimos el dataset en forma sintética\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5,\n",
        "random_state=11)\n",
        "# escala los datos (MinMaxScaler por defecto transforma todo entre 0 y 1)\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "# definimos el modelo\n",
        "model = LogisticRegression()\n",
        "# hacemos un k-flod cross val (k=10) múltiple\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "# evaluamos todos los modelos\n",
        "scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "# reportamos performance (promedio de todos los scores de accuracy de los modelos)\n",
        "print('Accuracy: %.3f (%.3f)' % (mean(scores)*100, std(scores)*100))\n",
        "scores\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_hgGFjbjJAP"
      },
      "source": [
        "## Forma correcta utilizando k-fold cross validation\n",
        "\n",
        "Debemos tener en cuenta que ahora el escalado debe ser aplicado a cada una de las particiones (recordar que con k-fold cv generaremos k modelos, y por lo tanto se deberá aplicar el preprocesamiento en cada caso).\n",
        "Para simplifica esto `scikitlearn` nos proporciona los `pipelines`, que condensa dentro de una misma estructura la secuencia de transformaciones u operaciones que se aplicarán sobre los datos. Un pipeline será una lista de tuplas, donde el primer elemento de cada tupla es un nombre que le damos a la transformación/procesamiento y el segundo el método asociado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-VrRoeSjNvk",
        "outputId": "ff590c2c-f6a2-4e40-ca9c-8f7a3615bd86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 83.100 (3.419)\n"
          ]
        }
      ],
      "source": [
        "# correct data preparation for model evaluation with k-fold cross-validation\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "# construimos el dataset en forma sintética\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5,\n",
        "random_state=11)\n",
        "# definimos la estructura del pipeline\n",
        "steps = [\n",
        "    ('scaler', MinMaxScaler()),    # Escaladoxcon MinMax\n",
        "    ('classifier', LogisticRegression())    # Modelo\n",
        "]\n",
        "# y construimos el objeto pipeline\n",
        "pipeline = Pipeline(steps)\n",
        "# hacemos un k-flod cross val (k=10) múltiple\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "# evaluamos el modelo, pero automáticamente aplica el pipeline en cada split\n",
        "scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "# report performance\n",
        "print('Accuracy: %.3f (%.3f)' % (mean(scores)*100, std(scores)*100))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TRhlpR4zyT7"
      },
      "source": [
        "Qué sucede si quiero ver la matriz de confusión asociada? Recordar que `RepeatedStratifiedKFold` genera múltiples k-fold cv para y promedia el scoring obtenido en cada particionamiento. En este caso usaremos solo `StratifiedKFold`, que genera un solo particionamiento y sobre ese particionamiento evaluaremos la matriz de confusión.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsUErwUy2mWb",
        "outputId": "9dc24671-7b8d-4888-a7a8-a61ef2205e92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8489999999999999\n",
            "Precision: 0.8450286653836226\n",
            "Recall: 0.8516940109929901\n",
            "F1 Score: 0.8479468459866044\n",
            "Confusion Matrix:\n",
            " [[424  77]\n",
            " [ 74 425]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_predict, cross_val_score, KFold\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Crear un conjunto de datos de ejemplo utilizando make_classification\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
        "\n",
        "# Crear el escalador MinMax\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Crear el modelo de regresión logística\n",
        "model = LogisticRegression()\n",
        "\n",
        "steps = [\n",
        "    ('scaler', MinMaxScaler()),    # Escaladoxcon MinMax\n",
        "    ('classifier', LogisticRegression())    # Modelo\n",
        "]\n",
        "\n",
        "# y construimos el objeto pipeline\n",
        "pipeline = Pipeline(steps)\n",
        "# Definir el número de splits para la validación cruzada (k)\n",
        "kf = KFold(n_splits=10)\n",
        "\n",
        "# Realizar validación cruzada y calcular las métricas utilizando el pipeline\n",
        "accuracy_scores = cross_val_score(pipeline, X, y, cv=kf, scoring='accuracy')\n",
        "precision_scores = cross_val_score(pipeline, X, y, cv=kf, scoring='precision')\n",
        "recall_scores = cross_val_score(pipeline, X, y, cv=kf, scoring='recall')\n",
        "f1_scores = cross_val_score(pipeline, X, y, cv=kf, scoring='f1')\n",
        "\n",
        "# Obtener predicciones para la matriz de confusión utilizando el pipeline\n",
        "# (notar que aplicamos el pipeline)\n",
        "y_pred = cross_val_predict(pipeline, X, y, cv=kf)\n",
        "\n",
        "# Calcular la matriz de confusión\n",
        "conf_matrix = confusion_matrix(y, y_pred)\n",
        "\n",
        "# Imprimir los resultados\n",
        "print(\"Accuracy:\", np.mean(accuracy_scores))\n",
        "print(\"Precision:\", np.mean(precision_scores))\n",
        "print(\"Recall:\", np.mean(recall_scores))\n",
        "print(\"F1 Score:\", np.mean(f1_scores))\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3i8v-HbEA5xX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYeGyvo6kDs8"
      },
      "source": [
        "# Data Cleaning\n",
        "La limpieza de datos se refiere a identificar y corregir errores en el dataset que pueden afectar negativamente en un modelo predictivo. Existen diferentes tipos de errores en un dataset, aunque los dos más simples son cuando las columnas que no contienen suficiente información y las filas aparecen duplicadas.\n",
        "\n",
        "## Identificando columnas que tienen un solo valor\n",
        "Las columnas que tienen un único valor son inútiles para el modelado. Estas columnas o predictores se denominan predictores de varianza cero y por lo tanto no tienen capacidad predictiva.\n",
        "\n",
        "El siguiente ejemplo usa el método `unique` de `Numpy`\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SG0MOqilldna"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odRL-hpnkItY",
        "outputId": "bc17281b-ef3d-495a-97d6-33c27fa76aed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 238\n",
            "1 297\n",
            "2 927\n",
            "3 933\n",
            "4 179\n",
            "5 375\n",
            "6 820\n",
            "7 618\n",
            "8 561\n",
            "9 57\n",
            "10 577\n",
            "11 59\n",
            "12 73\n",
            "13 107\n",
            "14 53\n",
            "15 91\n",
            "16 893\n",
            "17 810\n",
            "18 170\n",
            "19 53\n",
            "20 68\n",
            "21 9\n",
            "22 1\n",
            "23 92\n",
            "24 9\n",
            "25 8\n",
            "26 9\n",
            "27 308\n",
            "28 447\n",
            "29 392\n",
            "30 107\n",
            "31 42\n",
            "32 4\n",
            "33 45\n",
            "34 141\n",
            "35 110\n",
            "36 3\n",
            "37 758\n",
            "38 9\n",
            "39 9\n",
            "40 388\n",
            "41 220\n",
            "42 644\n",
            "43 649\n",
            "44 499\n",
            "45 2\n",
            "46 937\n",
            "47 169\n",
            "48 286\n",
            "49 2\n"
          ]
        }
      ],
      "source": [
        "# summarize the number of unique values for each column using numpy\n",
        "from numpy import loadtxt\n",
        "from numpy import unique\n",
        "# load the dataset\n",
        "\n",
        "data = loadtxt(\"https://github.com/gustavovazquez/datasets/raw/main/oil-spill.csv\", delimiter=',')\n",
        "# summarize the number of unique values in each column\n",
        "for i in range(data.shape[1]):\n",
        "    print(i, len(unique(data[:, i])))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J586nCQ3lgVW"
      },
      "source": [
        "aunque en forma más sencilla podemos usar `unique` de `Pandas`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVJE21LUllvo",
        "outputId": "348b1677-9fb5-48d6-f95c-ea4ebb1cb408"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0     238\n",
            "1     297\n",
            "2     927\n",
            "3     933\n",
            "4     179\n",
            "5     375\n",
            "6     820\n",
            "7     618\n",
            "8     561\n",
            "9      57\n",
            "10    577\n",
            "11     59\n",
            "12     73\n",
            "13    107\n",
            "14     53\n",
            "15     91\n",
            "16    893\n",
            "17    810\n",
            "18    170\n",
            "19     53\n",
            "20     68\n",
            "21      9\n",
            "22      1\n",
            "23     92\n",
            "24      9\n",
            "25      8\n",
            "26      9\n",
            "27    308\n",
            "28    447\n",
            "29    392\n",
            "30    107\n",
            "31     42\n",
            "32      4\n",
            "33     45\n",
            "34    141\n",
            "35    110\n",
            "36      3\n",
            "37    758\n",
            "38      9\n",
            "39      9\n",
            "40    388\n",
            "41    220\n",
            "42    644\n",
            "43    649\n",
            "44    499\n",
            "45      2\n",
            "46    937\n",
            "47    169\n",
            "48    286\n",
            "49      2\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# summarize the number of unique values for each column using nunique\n",
        "from pandas import read_csv\n",
        "# load the dataset\n",
        "df = read_csv(\"https://github.com/gustavovazquez/datasets/raw/main/oil-spill.csv\", header=None)\n",
        "# summarize the number of unique values in each column\n",
        "print(df.nunique())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuCi4zCElusu"
      },
      "source": [
        "## Borrando columnas con valores únicos\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ST0bQqUzl17G",
        "outputId": "8947fa4f-4b2b-4de5-f396-27ee9079db77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(937, 50)\n",
            "[22]\n",
            "(937, 49)\n"
          ]
        }
      ],
      "source": [
        "# delete columns with a single unique value\n",
        "from pandas import read_csv\n",
        "# load the dataset\n",
        "df = read_csv(\"https://github.com/gustavovazquez/datasets/raw/main/oil-spill.csv\", header=None)\n",
        "print(df.shape)\n",
        "# get number of unique values for each column\n",
        "counts = df.nunique()\n",
        "#print(counts)\n",
        "# record columns to delete\n",
        "to_del = [i for i,v in enumerate(counts) if v == 1]\n",
        "print(to_del)\n",
        "# drop useless columns\n",
        "df.drop(to_del, axis=1, inplace=True)\n",
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4Yg_AeSmVSS"
      },
      "source": [
        "## Trratamiento de columnas con baja varianza\n",
        "En ocasiones la poca varianza de un atributo también puede generar problemas al momento de modelar.\n",
        "La clase `VarianceThreshold` de  `scikit-learn` soporta esto como un tipo de feature selection.Se puede especificar el umbral como argumento, que por defecto es 0.0 para eliminar columnas con un solo valor. Luego se puede ajustar y aplicar a un conjunto de datos llamando al método `fit_transform()` para crear una versión transformada del conjunto de datos donde las columnas que tienen una variación inferior al umbral se han eliminado automáticamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oS78wORCnQL-",
        "outputId": "801db49d-9395-40ad-b1ca-6ccdc80859f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(937, 49) (937,)\n",
            "(937, 48)\n"
          ]
        }
      ],
      "source": [
        "# example of applying the variance threshold for feature selection\n",
        "from pandas import read_csv\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "# load the dataset\n",
        "df = read_csv(\"https://github.com/gustavovazquez/datasets/raw/main/oil-spill.csv\", header=None)\n",
        "# split data into inputs and outputs\n",
        "data = df.values\n",
        "X = data[:, :-1]\n",
        "y = data[:, -1]\n",
        "print(X.shape, y.shape)\n",
        "# define the transform\n",
        "transform = VarianceThreshold()\n",
        "# transform the input data\n",
        "X_sel = transform.fit_transform(X)\n",
        "print(X_sel.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mfDKk9snfAE"
      },
      "source": [
        "En el código anterior hemos usado el valor default y por lo tanto se eliminan columnas con valores únicos. Podemos también explorar cómo funciona para distintos valores de umbral:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        },
        "id": "NN0hLbs0nqdw",
        "outputId": "d81f3f64-a5e6-45c3-9a98-23e4ada45380"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(937, 49) (937,)\n",
            ">Threshold=0.00, Features=48\n",
            ">Threshold=0.05, Features=37\n",
            ">Threshold=0.10, Features=36\n",
            ">Threshold=0.15, Features=35\n",
            ">Threshold=0.20, Features=35\n",
            ">Threshold=0.25, Features=35\n",
            ">Threshold=0.30, Features=35\n",
            ">Threshold=0.35, Features=35\n",
            ">Threshold=0.40, Features=35\n",
            ">Threshold=0.45, Features=33\n",
            ">Threshold=0.50, Features=31\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# explore the effect of the variance thresholds on the number of selected features\n",
        "from numpy import arange\n",
        "from pandas import read_csv\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from matplotlib import pyplot\n",
        "# load the dataset\n",
        "df = read_csv(\"https://github.com/gustavovazquez/datasets/raw/main/oil-spill.csv\", header=None)\n",
        "# split data into inputs and outputs\n",
        "data = df.values\n",
        "X = data[:, :-1]\n",
        "y = data[:, -1]\n",
        "print(X.shape, y.shape)\n",
        "# define thresholds to check\n",
        "thresholds = arange(0.0, 0.55, 0.05)\n",
        "# apply transform with each threshold\n",
        "results = list()\n",
        "for t in thresholds:\n",
        "    # define the transform\n",
        "    transform = VarianceThreshold(threshold=t)\n",
        "    # transform the input data\n",
        "    X_sel = transform.fit_transform(X)\n",
        "    # determine the number of input features\n",
        "    n_features = X_sel.shape[1]\n",
        "    print('>Threshold=%.2f, Features=%d' % (t, n_features))\n",
        "    # store the result\n",
        "    results.append(n_features)\n",
        "# plot the threshold vs the number of selected features\n",
        "pyplot.plot(thresholds, results)\n",
        "pyplot.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Co5chqOAn-uo"
      },
      "source": [
        "## Identificando filas duplicadas\n",
        "Las muestras duplicadas en un dataset pueden perjudicar el modelado. Por ejemplo considere la situación cuando dos o más muestras están duplicadas y presentes tanto en los conjuntos de entrenamiento y test. Esto viola el principio de que los datos a predecir no pueden haber sido vistos en la etapa de entrenamiento, sobreestimado así el modelo.\n",
        "\n",
        "El método `duplicate` de `Pandas` informará si una fila determinada está duplicada o no. Todas las filas están marcadas como Falso para indicar que no es un duplicado o como Verdadero para indicar que lo es. Si hay duplicados, la primera aparición de la fila se marca como Falso (de forma predeterminada). El siguiente ejemplo busca duplicados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpjmnadinqj1",
        "outputId": "8e2ec437-3b6d-4574-9d3d-068d5b069a1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
            "142                5.8               2.7                5.1               1.9\n"
          ]
        }
      ],
      "source": [
        "# locate rows of duplicate data\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "# load the dataset\n",
        "iris = load_iris()\n",
        "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "# calculate duplicates\n",
        "dups = df.duplicated()\n",
        "# report if there are any duplicates\n",
        "print(dups.any())\n",
        "# list all duplicate rows\n",
        "print(df[dups])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFA1eSmDpiJr"
      },
      "source": [
        "Para borrar las filas duplicadas utilizaremos el método `row_duplicates`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ogcolh3zpmZ1",
        "outputId": "6b4c297f-af08-4276-e92c-37b537fb4f35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(150, 4)\n",
            "(149, 4)\n"
          ]
        }
      ],
      "source": [
        "# delete rows of duplicate data from the dataset\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "# load the dataset\n",
        "iris = load_iris()\n",
        "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "print(df.shape)\n",
        "# delete duplicate rows\n",
        "df.drop_duplicates(inplace=True)\n",
        "print(df.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4kVJ3IZpreC"
      },
      "source": [
        "# Outliers\n",
        "\n",
        "Un outlier es una observación en el conjunto de datos que escapa a la tendencia de los mismos. En algún sentido es una muestra atípica, distinta. Estos valores aparecen por diferentes causas:\n",
        "\n",
        "-\terrores de medición o en el ingreso de los datos\n",
        "-\tdatos corruptos\n",
        "-\taparición de verdaderos valores atípicos\n",
        "\n",
        "No existe una forma precisa para definir e identificar outliers en general. Es el experto del dominio quien debe interpretar las observaciones crudas que contiene el conjunto de datos y decidir cuando un valor es atípico o no. Sin embargo existen métodos estadísticos para facilitar la identificación de posibles candidatos.\n",
        "\n",
        "## Caso de estudio\n",
        "Definimos un conjunto de formado por 10000 números aleatorios provenientes de una distribución gaussiana con media 50 y desvío estándar de 5. Naturalmente los valores generados por esta distribución contendrá outliers por efecto de la distribución en sí (valores en los extremos de la distribución deberían ser identificados como atípicos).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27xS4qdXkvhN",
        "outputId": "08c6c3d3-a9ba-40da-ac20-9c4f10fe0a4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean=50.049 stdv=4.994\n"
          ]
        }
      ],
      "source": [
        "# generate gaussian data\n",
        "from numpy.random import seed\n",
        "from numpy.random import randn\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "# seed the random number generator\n",
        "seed(1)\n",
        "# generate univariate observations\n",
        "data = 5 * randn(10000) + 50\n",
        "# summarize\n",
        "print('mean=%.3f stdv=%.3f' % (mean(data), std(data)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgQT48dSszcA"
      },
      "source": [
        "## Método basado en el desvío estándar\n",
        "A partir de una distribución de Gauss o tipo gaussiana podemos usar el desvío estándar de una población como punto de corte para identificar outliers. La distribución de Gauss tiene la propiedad de que a partir de la media y en un entorno de un desvío estándar se ubicará el 68% de los Datos. Por ejemplo si la media es 50 y el desvío estándar es de 5 como en el ejemplo anterior, aproximadamente un 68% de los Datos caerán en el intervalo de 45 y 55. Podemos expandir el rango de cobertura de la siguiente manera:\n",
        "-\t1 desvío estándar de la media: 68%\n",
        "-\t2 desvíos estándar de la media: 95%\n",
        "-\t3 desvíos estándar de la media: 99,7%\n",
        "Los valores que caen por afuera de 3 desvíos estándar son parte de la distribución, pero son elementos raros que ocurren aproximadamente en una de 370 muestras. Tres desvíos estándar de la media es un punto de corte común en la práctica de identificar outliers en distribuciones de tipo gaussiana.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbbJijimstSm",
        "outputId": "15e2a69a-858c-4029-96a0-700a9a6eaf0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Identified outliers: 29\n",
            "Non-outlier observations: 9971\n"
          ]
        }
      ],
      "source": [
        "# identify outliers with standard deviation\n",
        "from numpy.random import seed\n",
        "from numpy.random import randn\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "# seed the random number generator\n",
        "seed(1)\n",
        "# generate univariate observations\n",
        "data = 5 * randn(10000) + 50\n",
        "# calculate summary statistics\n",
        "data_mean, data_std = mean(data), std(data)\n",
        "# define outliers\n",
        "cut_off = data_std * 3\n",
        "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
        "# identify outliers\n",
        "outliers = [x for x in data if x < lower or x > upper]\n",
        "print('Identified outliers: %d' % len(outliers))\n",
        "# remove outliers\n",
        "outliers_removed = [x for x in data if x >= lower and x <= upper]\n",
        "print('Non-outlier observations: %d' % len(outliers_removed))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vv5Exmvtu87K"
      },
      "source": [
        "## Método del rango intercuartil (Interquartile Range Method)\n",
        "No siempre los datos son normales como para ser tratados mediante una distribución gaussiana. Un buen estadístico para sumarizar una muestra de Datos de una distribución no gaussiana es el rango intercuartíl (IQR). El IQR se calcula como la diferencia entre los percentiles 75 y 25 de los datos. Recordar que los percentiles pueden calcularse ordenando las observaciones y seleccionando los valores en los índices específicos; el percentil 50 ese valor medio, o el promedio de los 2 en el medio en caso de que la cantidad de muestras sea impar.\n",
        "el IQR puede usarse para identificar valores definiendo límites en los valores de la muestra que están a un factor $k$ del IQR por debajo del percentil 25 o por encima del 75. Un valor tradicional es $k=1.5$. Un factor $k=3$ se usa para identificar valores extremadamente raros.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNPx3fo2vKL7",
        "outputId": "841acfe1-4721-4f17-b0c8-70de5bfd8058"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentiles: 25th=46.685, 75th=53.359, IQR=6.674\n",
            "Identified outliers: 81\n",
            "Non-outlier observations: 9919\n"
          ]
        }
      ],
      "source": [
        "# identify outliers with interquartile range\n",
        "from numpy.random import seed\n",
        "from numpy.random import randn\n",
        "from numpy import percentile\n",
        "# seed the random number generator\n",
        "seed(1)\n",
        "# generate univariate observations\n",
        "data = 5 * randn(10000) + 50\n",
        "# calculate interquartile range\n",
        "q25, q75 = percentile(data, 25), percentile(data, 75)\n",
        "iqr = q75 - q25\n",
        "print('Percentiles: 25th=%.3f, 75th=%.3f, IQR=%.3f' % (q25, q75, iqr))\n",
        "# calculate the outlier cutoff\n",
        "cut_off = iqr * 1.5\n",
        "lower, upper = q25 - cut_off, q75 + cut_off\n",
        "# identify outliers\n",
        "outliers = [x for x in data if x < lower or x > upper]\n",
        "print('Identified outliers: %d' % len(outliers))\n",
        "# remove outliers\n",
        "outliers_removed = [x for x in data if x >= lower and x <= upper]\n",
        "print('Non-outlier observations: %d' % len(outliers_removed))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RF6zYvdz9q33"
      },
      "source": [
        "# Identificar y remover valores faltantes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUKjNd71rsFD",
        "outputId": "8e03c15f-a6b0-49b9-c2a0-925d76b03dfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
            "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
            "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
            "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
            "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
            "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
            "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
            "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
            "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
            "\n",
            "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
            "count  768.000000                768.000000  768.000000  768.000000  \n",
            "mean    31.992578                  0.471876   33.240885    0.348958  \n",
            "std      7.884160                  0.331329   11.760232    0.476951  \n",
            "min      0.000000                  0.078000   21.000000    0.000000  \n",
            "25%     27.300000                  0.243750   24.000000    0.000000  \n",
            "50%     32.000000                  0.372500   29.000000    0.000000  \n",
            "75%     36.600000                  0.626250   41.000000    1.000000  \n",
            "max     67.100000                  2.420000   81.000000    1.000000  \n"
          ]
        }
      ],
      "source": [
        "# load the dataset and review rows\n",
        "from pandas import read_csv\n",
        "# load the dataset\n",
        "dataset = read_csv('https://raw.githubusercontent.com/gustavovazquez/datasets/main/pima-indians-diabetes.csv')\n",
        "# summarize the first 20 rows of data\n",
        "print(dataset.describe())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDqp7EHY8rUQ"
      },
      "source": [
        "Claramente se ven valores 0 en columnas que evidentemente no deberían tenerlos.\n",
        "Típicamente en un DataFrame los missing values son representados con la constante `NaN` y entonces procederemos a su reemplazo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HAIgHzt-mXk",
        "outputId": "5340f4ec-e107-4cab-aef0-0fe4ac49cb09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pregnancies                 0\n",
            "Glucose                     5\n",
            "BloodPressure               0\n",
            "SkinThickness               0\n",
            "Insulin                     0\n",
            "BMI                         0\n",
            "DiabetesPedigreeFunction    0\n",
            "Age                         0\n",
            "Outcome                     0\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-370891720.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  dataset['Glucose'].replace(to_replace = 0, value = nan, inplace=True)\n"
          ]
        }
      ],
      "source": [
        "# example of marking missing values with nan values\n",
        "from numpy import nan\n",
        "from pandas import read_csv\n",
        "# load the dataset\n",
        "dataset = read_csv('https://raw.githubusercontent.com/gustavovazquez/datasets/main/pima-indians-diabetes.csv')\n",
        "# replace '0' values with 'nan'\n",
        "dataset['Glucose'].replace(to_replace = 0, value = nan, inplace=True)\n",
        "# count the number of nan values in each column\n",
        "print(dataset.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxydxsfR-4YB"
      },
      "source": [
        "A los efectos de verificar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-i12sL_lJLW",
        "outputId": "b5de37fe-39ec-4ae5-8758-71073a1257ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count    763.000000\n",
            "mean     121.686763\n",
            "std       30.535641\n",
            "min       44.000000\n",
            "25%       99.000000\n",
            "50%      117.000000\n",
            "75%      141.000000\n",
            "max      199.000000\n",
            "Name: Glucose, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "print(dataset['Glucose'].describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1-gyoELAr8N"
      },
      "source": [
        "# Imputación de valores\n",
        "Un dataset puede tener valores faltantes (o valores anómalos). No es conveniente borrar muestras del dataset ya que eso reduce la cantidad de datos disponibles. Una técnica aceptada es la imputación de los valores faltantes utilizando alguna forma estadística. Algunos estadísticos que pueden utilizarse son:\n",
        "- la media, mediana o moda de una columna\n",
        "- un valor constante\n",
        "\n",
        "\n",
        "## Ejemplo - Horse Colic Dataset\n",
        "En este dataset los valores faltantes son indicados con el símbolo '?'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2hdc4okPmwJ",
        "outputId": "66df87c8-9fbb-4b1b-ad88-90a13f2844b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    0   1        2     3      4     5    6    7    8    9   ...    18    19  \\\n",
            "0  2.0   1   530101  38.5   66.0  28.0  3.0  3.0  NaN  2.0  ...  45.0   8.4   \n",
            "1  1.0   1   534817  39.2   88.0  20.0  NaN  NaN  4.0  1.0  ...  50.0  85.0   \n",
            "2  2.0   1   530334  38.3   40.0  24.0  1.0  1.0  3.0  1.0  ...  33.0   6.7   \n",
            "3  1.0   9  5290409  39.1  164.0  84.0  4.0  1.0  6.0  2.0  ...  48.0   7.2   \n",
            "4  2.0   1   530255  37.3  104.0  35.0  NaN  NaN  6.0  2.0  ...  74.0   7.4   \n",
            "\n",
            "    20   21   22  23     24  25  26  27  \n",
            "0  NaN  NaN  2.0   2  11300   0   0   2  \n",
            "1  2.0  2.0  3.0   2   2208   0   0   2  \n",
            "2  NaN  NaN  1.0   2      0   0   0   1  \n",
            "3  3.0  5.3  2.0   1   2208   0   0   1  \n",
            "4  NaN  NaN  2.0   2   4300   0   0   2  \n",
            "\n",
            "[5 rows x 28 columns]\n"
          ]
        }
      ],
      "source": [
        "# load dataset\n",
        "dataframe = read_csv('https://raw.githubusercontent.com/gustavovazquez/datasets/main/horse-colic.csv', header=None, na_values='?')\n",
        "# summarize the first few rows\n",
        "print(dataframe.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ucg716_pPyy4"
      },
      "source": [
        "Sumarizamos la cantidad de missing values para cada columna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s57IZIBEQIFf",
        "outputId": "56c8a2fa-b1ad-4acc-81fa-facb3eb982ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> 0, Missing: 1 (0.3%)\n",
            "> 1, Missing: 0 (0.0%)\n",
            "> 2, Missing: 0 (0.0%)\n",
            "> 3, Missing: 60 (20.0%)\n",
            "> 4, Missing: 24 (8.0%)\n",
            "> 5, Missing: 58 (19.3%)\n",
            "> 6, Missing: 56 (18.7%)\n",
            "> 7, Missing: 69 (23.0%)\n",
            "> 8, Missing: 47 (15.7%)\n",
            "> 9, Missing: 32 (10.7%)\n",
            "> 10, Missing: 55 (18.3%)\n",
            "> 11, Missing: 44 (14.7%)\n",
            "> 12, Missing: 56 (18.7%)\n",
            "> 13, Missing: 104 (34.7%)\n",
            "> 14, Missing: 106 (35.3%)\n",
            "> 15, Missing: 247 (82.3%)\n",
            "> 16, Missing: 102 (34.0%)\n",
            "> 17, Missing: 118 (39.3%)\n",
            "> 18, Missing: 29 (9.7%)\n",
            "> 19, Missing: 33 (11.0%)\n",
            "> 20, Missing: 165 (55.0%)\n",
            "> 21, Missing: 198 (66.0%)\n",
            "> 22, Missing: 1 (0.3%)\n",
            "> 23, Missing: 0 (0.0%)\n",
            "> 24, Missing: 0 (0.0%)\n",
            "> 25, Missing: 0 (0.0%)\n",
            "> 26, Missing: 0 (0.0%)\n",
            "> 27, Missing: 0 (0.0%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4001878281.py:6: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
            "  print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))\n",
            "/tmp/ipython-input-4001878281.py:6: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
            "  print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))\n",
            "/tmp/ipython-input-4001878281.py:6: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
            "  print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))\n",
            "/tmp/ipython-input-4001878281.py:6: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
            "  print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))\n",
            "/tmp/ipython-input-4001878281.py:6: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
            "  print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))\n",
            "/tmp/ipython-input-4001878281.py:6: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
            "  print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))\n",
            "/tmp/ipython-input-4001878281.py:6: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
            "  print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))\n",
            "/tmp/ipython-input-4001878281.py:6: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
            "  print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))\n",
            "/tmp/ipython-input-4001878281.py:6: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
            "  print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))\n",
            "/tmp/ipython-input-4001878281.py:6: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
            "  print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))\n",
            "/tmp/ipython-input-4001878281.py:6: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
            "  print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))\n",
            "/tmp/ipython-input-4001878281.py:6: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
            "  print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))\n",
            "/tmp/ipython-input-4001878281.py:6: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
            "  print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))\n",
            "/tmp/ipython-input-4001878281.py:6: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
            "  print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))\n",
            "/tmp/ipython-input-4001878281.py:6: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
            "  print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))\n",
            "/tmp/ipython-input-4001878281.py:6: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
            "  print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))\n",
            "/tmp/ipython-input-4001878281.py:6: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
            "  print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))\n",
            "/tmp/ipython-input-4001878281.py:6: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
            "  print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))\n",
            "/tmp/ipython-input-4001878281.py:6: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
            "  print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))\n",
            "/tmp/ipython-input-4001878281.py:6: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
            "  print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))\n",
            "/tmp/ipython-input-4001878281.py:6: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
            "  print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))\n",
            "/tmp/ipython-input-4001878281.py:6: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
            "  print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))\n",
            "/tmp/ipython-input-4001878281.py:6: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
            "  print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))\n",
            "/tmp/ipython-input-4001878281.py:6: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
            "  print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))\n",
            "/tmp/ipython-input-4001878281.py:6: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
            "  print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))\n",
            "/tmp/ipython-input-4001878281.py:6: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
            "  print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))\n",
            "/tmp/ipython-input-4001878281.py:6: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
            "  print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))\n",
            "/tmp/ipython-input-4001878281.py:6: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
            "  print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))\n",
            "/tmp/ipython-input-4001878281.py:6: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
            "  print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))\n",
            "/tmp/ipython-input-4001878281.py:6: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
            "  print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))\n",
            "/tmp/ipython-input-4001878281.py:6: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
            "  print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))\n",
            "/tmp/ipython-input-4001878281.py:6: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
            "  print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))\n",
            "/tmp/ipython-input-4001878281.py:6: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
            "  print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))\n",
            "/tmp/ipython-input-4001878281.py:6: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
            "  print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))\n",
            "/tmp/ipython-input-4001878281.py:6: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
            "  print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))\n",
            "/tmp/ipython-input-4001878281.py:6: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
            "  print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))\n",
            "/tmp/ipython-input-4001878281.py:6: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
            "  print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))\n",
            "/tmp/ipython-input-4001878281.py:6: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
            "  print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))\n",
            "/tmp/ipython-input-4001878281.py:6: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
            "  print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))\n",
            "/tmp/ipython-input-4001878281.py:6: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
            "  print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))\n",
            "/tmp/ipython-input-4001878281.py:6: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
            "  print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))\n",
            "/tmp/ipython-input-4001878281.py:6: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
            "  print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))\n",
            "/tmp/ipython-input-4001878281.py:6: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
            "  print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))\n",
            "/tmp/ipython-input-4001878281.py:6: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
            "  print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))\n",
            "/tmp/ipython-input-4001878281.py:6: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
            "  print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))\n",
            "/tmp/ipython-input-4001878281.py:6: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
            "  print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))\n",
            "/tmp/ipython-input-4001878281.py:6: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
            "  print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))\n",
            "/tmp/ipython-input-4001878281.py:6: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
            "  print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))\n",
            "/tmp/ipython-input-4001878281.py:6: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
            "  print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))\n",
            "/tmp/ipython-input-4001878281.py:6: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
            "  print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))\n",
            "/tmp/ipython-input-4001878281.py:6: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
            "  print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))\n",
            "/tmp/ipython-input-4001878281.py:6: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
            "  print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))\n",
            "/tmp/ipython-input-4001878281.py:6: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
            "  print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))\n",
            "/tmp/ipython-input-4001878281.py:6: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
            "  print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))\n",
            "/tmp/ipython-input-4001878281.py:6: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
            "  print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))\n",
            "/tmp/ipython-input-4001878281.py:6: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
            "  print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))\n"
          ]
        }
      ],
      "source": [
        "# summarize the number of rows with missing values for each column\n",
        "for i in range(dataframe.shape[1]):\n",
        "  # count number of rows with missing values\n",
        "  n_miss = dataframe[[i]].isnull().sum()\n",
        "  perc = n_miss / dataframe.shape[0] * 100\n",
        "  print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmHk5sl4QhEO"
      },
      "source": [
        "# Imputación estadística con SimpleImputer\n",
        "\n",
        "SimpleImputer es una transformación que permite aplicar un estadístico para imputar valores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RtJqA6JQ1hr",
        "outputId": "fd0614fe-3975-474b-ecb4-d7bb48dcfd26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing: 1605\n",
            "Missing: 0\n"
          ]
        }
      ],
      "source": [
        "# statistical imputation transform for the horse colic dataset\n",
        "from numpy import isnan\n",
        "from pandas import read_csv\n",
        "from sklearn.impute import SimpleImputer\n",
        "# load dataset\n",
        "dataframe = read_csv('https://raw.githubusercontent.com/gustavovazquez/datasets/main/horse-colic.csv', header=None, na_values='?')\n",
        "# split into input and output elements\n",
        "data = dataframe.values\n",
        "ix = [i for i in range(data.shape[1]) if i != 23]\n",
        "X, y = data[:, ix], data[:, 23]\n",
        "# summarize total missing\n",
        "print('Missing: %d' % sum(isnan(X).flatten()))\n",
        "# define imputer\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "# fit on the dataset\n",
        "imputer.fit(X)\n",
        "# transform the dataset\n",
        "Xtrans = imputer.transform(X)\n",
        "# summarize total missing\n",
        "print('Missing: %d' % sum(isnan(Xtrans).flatten()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcXWcN6eRXxk"
      },
      "source": [
        "## SimpleImputer y la evaluación de un modelo\n",
        "Siempre que queremos evaluar un modelo usando k-fold cross-validation debemos evitar el data leakage. Para aplicar la imputación en forma correcta, el estadístico a aplicar debe calcularse en las columnas de los folds que se usan en el entrenamiento para luego ser aplicados tanto al entrenamiento como al testeo. Para simplificar el proceso, esto puede hacerse creando un pipeline de procesamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bs7JkHUuSN37",
        "outputId": "4c2792ea-53dd-4fdf-ffd0-19e01bdee23d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Accuracy: 0.867 (0.047)\n"
          ]
        }
      ],
      "source": [
        "# evaluate mean imputation and random forest for the horse colic dataset\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from pandas import read_csv\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "# load dataset\n",
        "dataframe = read_csv('https://raw.githubusercontent.com/gustavovazquez/datasets/main/horse-colic.csv', header=None, na_values='?')\n",
        "# split into input and output elements\n",
        "data = dataframe.values\n",
        "ix = [i for i in range(data.shape[1]) if i != 23]\n",
        "X, y = data[:, ix], data[:, 23]\n",
        "# define modeling pipeline\n",
        "model = RandomForestClassifier()\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "pipeline = Pipeline(steps=[('i', imputer), ('m', model)])\n",
        "# define model evaluation\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "# evaluate model\n",
        "scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "print('Mean Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFpv3Tq0Silr"
      },
      "source": [
        "## Comparando la imputación de diferentes estadísticos\n",
        "¿Es siempre la media el mejor estadístico para usar? En principio no podemos saberlo, pero podemos probar las diferentes opciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "GIld18UKS0r8",
        "outputId": "546adea0-52ba-4b97-e660-5042d0c841f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">mean 0.863 (0.050)\n",
            ">median 0.868 (0.059)\n",
            ">most_frequent 0.868 (0.057)\n",
            ">constant 0.874 (0.051)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4129781765.py:30: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
            "  pyplot.boxplot(results, labels=strategies, showmeans=True)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# compare statistical imputation strategies for the horse colic dataset\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from pandas import read_csv\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from matplotlib import pyplot\n",
        "# load dataset\n",
        "dataframe = read_csv('https://raw.githubusercontent.com/gustavovazquez/datasets/main/horse-colic.csv', header=None, na_values='?')\n",
        "# split into input and output elements\n",
        "data = dataframe.values\n",
        "ix = [i for i in range(data.shape[1]) if i != 23]\n",
        "X, y = data[:, ix], data[:, 23]\n",
        "# evaluate each strategy on the dataset\n",
        "results = list()\n",
        "strategies = ['mean', 'median', 'most_frequent', 'constant']\n",
        "for s in strategies:\n",
        "  # create the modeling pipeline\n",
        "  pipeline = Pipeline(steps=[('i', SimpleImputer(strategy=s)), ('m', RandomForestClassifier())])\n",
        "  # evaluate the model\n",
        "  cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "  scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # store results\n",
        "  results.append(scores)\n",
        "  print('>%s %.3f (%.3f)' % (s, mean(scores), std(scores)))\n",
        "# plot model performance for comparison\n",
        "pyplot.boxplot(results, labels=strategies, showmeans=True)\n",
        "pyplot.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzmKaLfITVFg"
      },
      "source": [
        "## SimpleImputer al momento de realizar una predicción\n",
        "Las muestras a predecir también pueden incluir valores faltantes, por lo tanto debe aplicarse la misma transformación usada en el entrenamiento. Para esto incluimos el pipeline de la transformación antes de invocar al método `predict`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jr0p3yt5Tx3p",
        "outputId": "e20fdf63-a7ca-4816-b9b7-1af39937b077"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Class: 2\n"
          ]
        }
      ],
      "source": [
        "# constant imputation strategy and prediction for the horse colic dataset\n",
        "from numpy import nan\n",
        "from pandas import read_csv\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "# load dataset\n",
        "dataframe = read_csv('https://raw.githubusercontent.com/gustavovazquez/datasets/main/horse-colic.csv', header=None, na_values='?')\n",
        "# split into input and output elements\n",
        "data = dataframe.values\n",
        "ix = [i for i in range(data.shape[1]) if i != 23]\n",
        "X, y = data[:, ix], data[:, 23]\n",
        "# create the modeling pipeline\n",
        "pipeline = Pipeline(steps=[('i', SimpleImputer(strategy='constant')), ('m', RandomForestClassifier())])\n",
        "# fit the model\n",
        "pipeline.fit(X, y)\n",
        "# define new data\n",
        "row = [2, 1, 530101, 38.50, 66, 28, 3, 3, nan, 2, 5, 4, 4, nan, nan, nan, 3, 5, 45.00, 8.40, nan, nan, 2, 11300, 00000, 00000, 2]\n",
        "# make a prediction\n",
        "yhat = pipeline.predict([row])\n",
        "# summarize prediction\n",
        "print('Predicted Class: %d' % yhat[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8m5QXd5UDG3"
      },
      "source": [
        "# Imputación mediante un método de aprendizaje\n",
        "Un enfoque muy utilizado es el uso de modelos de aprendizaje automático para inferir el valor de un dato no disponible. La desventaja principal es que esto requiere ajustar un modelo para cada variable que contiene datos faltantes. Si bien puede usarse cualquier método, KNN suele ser muy efectivo (la técnica se suele denominar nearest neighbor imputation).\n",
        "Scikit-learn directamente proporciona la clase `KNNImputer` para esta tarea.   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfE0jfkzVW2i",
        "outputId": "e1c9dd5c-53d5-4d3b-a654-5df87168fc80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing: 1605\n",
            "Missing: 0\n"
          ]
        }
      ],
      "source": [
        "# knn imputation transform for the horse colic dataset\n",
        "from numpy import isnan\n",
        "from pandas import read_csv\n",
        "from sklearn.impute import KNNImputer\n",
        "# load dataset\n",
        "dataframe = read_csv('https://raw.githubusercontent.com/gustavovazquez/datasets/main/horse-colic.csv', header=None, na_values='?')\n",
        "# split into input and output elements\n",
        "data = dataframe.values\n",
        "ix = [i for i in range(data.shape[1]) if i != 23]\n",
        "X, y = data[:, ix], data[:, 23]\n",
        "# summarize total missing\n",
        "print('Missing: %d' % sum(isnan(X).flatten()))\n",
        "# define imputer\n",
        "imputer = KNNImputer()\n",
        "# fit on the dataset\n",
        "imputer.fit(X)\n",
        "# transform the dataset\n",
        "Xtrans = imputer.transform(X)\n",
        "# summarize total missing\n",
        "print('Missing: %d' % sum(isnan(Xtrans).flatten()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lHjj0Cik-J-"
      },
      "source": [
        "#Power Transform\n",
        "Busca transformar los datos a una forma gausiana o 'gaussian like'.\n",
        "Las dos transformaciones principales son:\n",
        "- Box-Cox Transform\n",
        "- Yeo-Johnson Transform\n",
        "\n",
        "Box-Cox propone una familia de transformaciones controladas por una parámetro $λ$:\n",
        "\n",
        "- $λ$ = −1.0 es una transformación recíproca\n",
        "- $λ$ = −0.5 es la raiz cuadrada de la transformación recíproca\n",
        "- $λ$ = 0.0 es una transformación logarítmica\n",
        "- $λ$ = 0.5 es una transformación raíz cuadrada\n",
        "- $λ$ = 1.0 no produce transformación\n",
        "\n",
        "Una vez determinado el parámetro $λ$ (siempre en el conjunto de entrenamiento) puede aplicarse la transformacón en el conjunto de test.\n",
        "\n",
        "En scikitlearn se dispone del método `PowerTransformer` que automáticamente determina el parámetro $λ$ para cada variable.\n",
        "\n",
        "# Ejemplo con dataset Sonar\n",
        "\n",
        "Primero desarrollamos un modelo sin transformar sus elementos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "zFVNisA1pUJB",
        "outputId": "efbf453c-a7ff-46e7-93ba-1a9c3cc0a0f6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.721 (0.041)\n"
          ]
        }
      ],
      "source": [
        "# evaluate knn on the raw sonar dataset\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "# load dataset\n",
        "dataframe = read_csv('https://raw.githubusercontent.com/gustavovazquez/datasets/main/sonar.csv', header=None)\n",
        "data = dataset.values\n",
        "\n",
        "# separate into input and output columns\n",
        "X, y = data[:, :-1], data[:, -1]\n",
        "# ensure inputs are floats and output is an integer label\n",
        "X = X.astype('float32')\n",
        "# define imputer\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "# fit on the dataset\n",
        "imputer.fit(X)\n",
        "# transform the dataset\n",
        "X = imputer.transform(X)\n",
        "y = LabelEncoder().fit_transform(y.astype('str'))\n",
        "# define and configure the model\n",
        "model = KNeighborsClassifier()\n",
        "# histograms of the variables\n",
        "fig = dataset.hist(xlabelsize=4, ylabelsize=4)\n",
        "[x.title.set_size(4) for x in fig.ravel()]\n",
        "# show the plot\n",
        "pyplot.show()\n",
        "\n",
        "# evaluate the model\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "# report model performance\n",
        "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZAG9JiUpqdi"
      },
      "source": [
        "Ahora aplicamos la transformación Box-Cox (escalamos los datos pues Box-Cox no acepta valores negativos)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "Q8HIArHZq0UZ",
        "outputId": "ded500d2-7e2d-4208-e195-9e9f1ed0155c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# visualize a box-cox transform of the scaled sonar dataset\n",
        "from pandas import read_csv\n",
        "from pandas import DataFrame\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from matplotlib import pyplot\n",
        "# Load dataset\n",
        "dataframe = read_csv('https://raw.githubusercontent.com/gustavovazquez/datasets/main/sonar.csv', header=None)\n",
        "# retrieve just the numeric input values\n",
        "data = dataset.values[:, :-1]\n",
        "# perform a box-cox transform of the dataset\n",
        "scaler = MinMaxScaler(feature_range=(1, 2))\n",
        "power = PowerTransformer(method='box-cox')\n",
        "pipeline = Pipeline(steps=[('s', scaler),('p', power)])\n",
        "data = pipeline.fit_transform(data)\n",
        "# convert the array back to a dataframe\n",
        "dataset = DataFrame(data)\n",
        "# histograms of the variables\n",
        "fig = dataset.hist(xlabelsize=4, ylabelsize=4)\n",
        "[x.title.set_size(4) for x in fig.ravel()]\n",
        "# show the plot\n",
        "pyplot.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6k4_P9orfB1"
      },
      "source": [
        "Luego el modelo es"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EY2F2-QrgbS",
        "outputId": "ae7bb400-2494-46a8-fe3b-0075f5c756e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.063 (0.026)\n"
          ]
        }
      ],
      "source": [
        "# evaluate knn on the box-cox sonar dataset\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "# load dataset\n",
        "dataframe = read_csv('https://raw.githubusercontent.com/gustavovazquez/datasets/main/sonar.csv', header=None)\n",
        "data = dataset.values\n",
        "# separate into input and output columns\n",
        "X, y = data[:, :-1], data[:, -1]\n",
        "# ensure inputs are floats and output is an integer label\n",
        "X = X.astype('float32')\n",
        "y = LabelEncoder().fit_transform(y.astype('str'))\n",
        "# define the pipeline\n",
        "scaler = MinMaxScaler(feature_range=(1, 2))\n",
        "power = PowerTransformer(method='box-cox')\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "model = KNeighborsClassifier()\n",
        "pipeline = Pipeline(steps=[('s', scaler),('p', power), ('i', imputer), ('m', model)])\n",
        "# evaluate the pipeline\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "n_scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "# report pipeline performance\n",
        "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwbcJIMv09eD"
      },
      "source": [
        "# Selección de atributos\n",
        "La selección de atributos en un problema de aprendizaje supervisado puede hacerse de diversas maneras. Las técnicas para descartar variables que aportan poca información para predecir la variable dependiente (por ejemplo variables con valores constantes o mínima varianza) son una forma fundamental y trivial para realizar esto. También la correlación entre una una variable independiente y la variable dependiente es una medida de importancia del predictor (siempre pensando en un contexto de modelos lineales).\n",
        "También los propios modelos de aprendizaje por la formulación matemática en la cual se basan tienen su propio mecanismo de selección de atributos. Por ejemplo en un modelo de regresión lineal por mínimos cuadrados o regresión logística, cuando se aplican técnicas de regularización implícitamente se realiza una selección de los mejores atributos pues los coeficientes de la regresión que son forzados a cero se asumen como no relevantes para el modelo. Los árboles de decisión, Random forest y los métodos de Boosting en general también tienen formas en su proceso de entrenamiento que permiten identificar los atributos más útiles para un determinado modelo (y obviamente un determinado data set).\n",
        "\n",
        "## Filter-based feature selection\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOILzlpG8A5g",
        "outputId": "139eb902-2fe6-464d-dc1f-b8ef82c9a421"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        "X, y = load_iris(return_X_y=True)\n",
        "X.shape\n",
        "X_new = SelectKBest(f_classif, k=2).fit_transform(X, y)\n",
        "X_new.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4adcm-m8_LTZ"
      },
      "source": [
        "## Wrapper-based feature selection\n",
        "\n",
        "\n",
        "## RFE (Recursive Feature Elimination)\n",
        "\n",
        "Dado un estimador o modelo que asigna un score de importancia de las variables independientes (por ejemplo, los coeficientes de un modelo lineal), el objetivo de la eliminación recursiva de features (RFE) es seleccionarlos recursivamente. Aquí es que aparece el concepto de wrapper: el método \"externo\" realiza la selección en forma recursiva, pero a partir de lo que va informando el modelo \"wrappeado\" de cómo es la importancia de cada predictor. Primero, el modelo se entrena en el conjunto inicial de predictores y la importancia de cada predictor  se obtiene a través del modelo que lo implementa (como coef_, feature_importances_). Luego, los predictores menos importantes se eliminan del conjunto de características actual. Este procedimiento se repite recursivamente en el conjunto podado hasta que finalmente se alcanza el número deseado de features para seleccionar.\n",
        "\n",
        "### Algoritmo\n",
        "\n",
        "El algoritmo de Recursive Feature Extraction opera mediante los siguientes pasos:\n",
        "\n",
        "- 1) Selección Inicial: Inicialmente, se entrena un modelo utilizando todas las características disponibles en el conjunto de datos. Se evalúa la importancia relativa de cada característica en función de su contribución al rendimiento del modelo.\n",
        "\n",
        "- 2) Eliminación de Características: Se procede a eliminar las características consideradas menos relevantes. Estas características aportan información limitada al modelo y, en algunos casos, pueden incluso introducir ruido en la interpretación de los datos.\n",
        "\n",
        "- 3) Nuevo Entrenamiento: El modelo se vuelve a entrenar utilizando únicamente las características que no han sido eliminadas en el paso anterior. Esto permite al modelo adaptarse a la nueva configuración de características y afinar su capacidad predictiva.\n",
        "\n",
        "- 4) Iteración Recursiva: Los pasos 2 y 3 se repiten en una forma recursiva. En cada iteración, se identifican y eliminan las características menos importantes, seguidas de un nuevo proceso de entrenamiento. Esta secuencia se repite hasta alcanzar un criterio de terminación, que podría ser un número predefinido de características o una métrica específica.\n",
        "\n",
        "- 5) Resultado Final: Al completar las iteraciones, se obtiene un conjunto de características seleccionadas que se consideran las más influyentes para el modelo. Estas características depuradas y significativas pueden ser empleadas en la construcción de modelos más simplificados y efectivos.\n",
        "\n",
        "En la implementación de RFE es necesario indicar el número de variables a seleccionar. Si se desea hacer el cálculo en forma automática, RFECV realiza RFE en un ciclo de validación cruzada para encontrar la cantidad óptima de características.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EpPxh61CUN9",
        "outputId": "9ce49e65-65b0-4e0c-cd4d-775a87b9def2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal number of features: 5\n"
          ]
        }
      ],
      "source": [
        "# ejemplo de utilización de RFECV\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "X, y = make_classification(\n",
        "    n_samples=500,\n",
        "    n_features=15,\n",
        "    n_informative=5,\n",
        "    n_redundant=2,\n",
        "    n_repeated=0,\n",
        "    n_classes=8,\n",
        "    n_clusters_per_class=1,\n",
        "    class_sep=0.8,\n",
        "    random_state=0,\n",
        ")\n",
        "\n",
        "min_features_to_select = 1  # Minimum number of features to consider\n",
        "clf = LogisticRegression()\n",
        "cv = StratifiedKFold(5)\n",
        "\n",
        "rfecv = RFECV(\n",
        "    estimator=clf,\n",
        "    step=1,\n",
        "    cv=cv,\n",
        "    scoring=\"accuracy\",\n",
        ")\n",
        "rfecv.fit(X, y)\n",
        "\n",
        "print(f\"Optimal number of features: {rfecv.n_features_}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zx49Lk4QdKf"
      },
      "source": [
        "Otra forma de Wrapper-based method es SequentialFeatureSelector, similar a RFE, pero con la particularidad de que puede empezar con un conjunto de atributos seleccionados vacío, para ir agregando en cada iteración (puede ser forward o backward)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPGaQXTBzMAI"
      },
      "source": [
        "# Metodo Permutation Importance\n",
        "\n",
        "## Introduccion teorica\n",
        "\n",
        "El metodo de importancia por permutacion pertenece a la familia de los metodos de interpretacion modelo-agnosticos.  \n",
        "Esto significa que puede aplicarse a cualquier modelo de machine learning, sin importar su estructura interna ni su tipo de entrenamiento.\n",
        "\n",
        "La idea principal es medir el efecto que tiene cada variable sobre el rendimiento del modelo una vez que este ya esta entrenado.  \n",
        "En lugar de observar coeficientes o pesos internos del modelo (como en una regresion lineal o en un arbol de decision), este metodo analiza como cambia la capacidad predictiva del modelo cuando se altera deliberadamente la informacion de una variable.\n",
        "\n",
        "El principio teorico se basa en la siguiente idea:\n",
        "\n",
        "**Si una variable es realmente importante, entonces romper la relacion entre esa variable y el objetivo deberia deteriorar significativamente la precision del modelo.**\n",
        "\n",
        "Si al alterar la variable el modelo sigue funcionando igual, se concluye que esa variable tiene poca o ninguna relevancia en las predicciones.\n",
        "\n",
        "---\n",
        "\n",
        "## Funcionamiento paso a paso\n",
        "\n",
        "1. Se parte de un modelo ya entrenado y de un conjunto de prueba (X_test, y_test).\n",
        "2. Se calcula una medida de rendimiento base del modelo (por ejemplo R2, accuracy o error cuadratico medio).\n",
        "3. Para cada variable Xj se realiza lo siguiente:\n",
        "   a. Se permutan aleatoriamente los valores de Xj en el conjunto de prueba, manteniendo las demas variables iguales.  \n",
        "   b. Se predice nuevamente con el modelo utilizando esta version permutada de X_test.  \n",
        "   c. Se calcula el nuevo rendimiento del modelo con los datos alterados.  \n",
        "   d. Se mide la diferencia entre el rendimiento original y el rendimiento con la variable permutada.  \n",
        "4. Esta diferencia representa la importancia de la variable Xj.  \n",
        "   Cuanto mayor sea la perdida de rendimiento, mayor es la importancia de la variable.\n",
        "\n",
        "El resultado se suele normalizar o promediar sobre varias repeticiones para reducir el efecto del azar.\n",
        "\n",
        "---\n",
        "\n",
        "## Interpretacion teorica\n",
        "\n",
        "La importancia por permutacion mide la contribucion marginal de cada variable en el contexto del modelo ya aprendido.  \n",
        "No mide la relacion estadistica directa con la variable objetivo, sino la perdida efectiva de informacion que sufre el modelo al desorganizar una variable.\n",
        "\n",
        "Por esta razon, el metodo tiene una interpretacion causal mas cercana al funcionamiento real del modelo.  \n",
        "Si el modelo aprendio interacciones o relaciones no lineales, la permutacion de una sola variable puede mostrar una caida grande en el rendimiento, lo que indica su participacion dentro de una relacion conjunta.\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM5DXL/8pwruchlurCgZ2i3",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}