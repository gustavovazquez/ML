{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMbu4tIDNC42fs9KJ41Hf06",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gustavovazquez/ML/blob/main/ML_Naive_Bayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Naive Bayes: Teor√≠a\n",
        "\n",
        "## 1. Concepto general\n",
        "\n",
        "El **clasificador Naive Bayes** es un modelo de aprendizaje supervisado **probabil√≠stico**, basado en el **Teorema de Bayes**, que asume que las variables predictoras son **condicionalmente independientes** entre s√≠ dado el valor de la clase.\n",
        "\n",
        "Se utiliza principalmente para **clasificaci√≥n**, especialmente en problemas de texto, diagn√≥stico o decisiones bajo incertidumbre.\n",
        "\n",
        "---\n",
        "\n",
        "##  2. Teorema de Bayes\n",
        "\n",
        "El teorema de Bayes establece que:\n",
        "\n",
        "$$\n",
        "P(C_k \\mid X) = \\frac{P(X \\mid C_k)\\,P(C_k)}{P(X)}\n",
        "$$\n",
        "\n",
        "Donde:\n",
        "\n",
        "- $C_k$ : una clase posible (por ejemplo, \"Spam\" o \"No spam\")\n",
        "- $X = (x_1, x_2, \\dots, x_n)$ : el conjunto de caracter√≠sticas observadas\n",
        "- $P(C_k)$ : probabilidad previa de la clase\n",
        "- $P(X \\mid C_k)$ : probabilidad de observar $X$ si la clase es $C_k$\n",
        "- $P(X)$ : probabilidad total de observar $X$ (constante para todas las clases)\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Suposici√≥n ‚ÄúNaive‚Äù\n",
        "\n",
        "El modelo **asume independencia condicional** entre los atributos:\n",
        "\n",
        "$$\n",
        "P(X \\mid C_k) = \\prod_{i=1}^{n} P(x_i \\mid C_k)\n",
        "$$\n",
        "\n",
        "Entonces, la probabilidad posterior se simplifica como:\n",
        "\n",
        "$$\n",
        "P(C_k \\mid X) \\propto P(C_k) \\prod_{i=1}^{n} P(x_i \\mid C_k)\n",
        "$$\n",
        "\n",
        "El s√≠mbolo $\\propto$ significa ‚Äú**proporcional a**‚Äù.  \n",
        "Como $P(X)$ es igual para todas las clases, no se necesita para comparar.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Regla de decisi√≥n\n",
        "\n",
        "El modelo elige la clase con la mayor probabilidad posterior:\n",
        "\n",
        "$$\n",
        "\\hat{C} = \\arg\\max_{C_k} P(C_k) \\prod_{i=1}^{n} P(x_i \\mid C_k)\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Variantes del modelo\n",
        "\n",
        "1. **Bernoulli Naive Bayes** ‚Üí para variables binarias (presencia/ausencia).  \n",
        "2. **Multinomial Naive Bayes** ‚Üí para conteos (frecuencia de palabras, n-gramas, etc.).  \n",
        "3. **Gaussian Naive Bayes** ‚Üí para variables continuas (asume distribuci√≥n normal).\n",
        "\n"
      ],
      "metadata": {
        "id": "_SrKO7P4RCRY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "## 6. Ejemplo: \"Play Tennis\"\n",
        "\n",
        "Queremos predecir si se juega al tenis seg√∫n las condiciones clim√°ticas.\n",
        "\n",
        "### Dataset\n",
        "\n",
        "| D√≠a | Outlook  | Temperature | Humidity | Wind  | PlayTennis |\n",
        "|:----|:----------|:------------|:----------|:------|:------------|\n",
        "| D1  | Sunny     | Hot         | High      | Weak  | No          |\n",
        "| D2  | Sunny     | Hot         | High      | Strong| No          |\n",
        "| D3  | Overcast  | Hot         | High      | Weak  | Yes         |\n",
        "| D4  | Rain      | Mild        | High      | Weak  | Yes         |\n",
        "| D5  | Rain      | Cool        | Normal    | Weak  | Yes         |\n",
        "| D6  | Rain      | Cool        | Normal    | Strong| No          |\n",
        "| D7  | Overcast  | Cool        | Normal    | Strong| Yes         |\n",
        "| D8  | Sunny     | Mild        | High      | Weak  | No          |\n",
        "| D9  | Sunny     | Cool        | Normal    | Weak  | Yes         |\n",
        "| D10 | Rain      | Mild        | Normal    | Weak  | Yes         |\n",
        "| D11 | Sunny     | Mild        | Normal    | Strong| Yes         |\n",
        "| D12 | Overcast  | Mild        | High      | Strong| Yes         |\n",
        "| D13 | Overcast  | Hot         | Normal    | Weak  | Yes         |\n",
        "| D14 | Rain      | Mild        | High      | Strong| No          |\n",
        "\n",
        "---\n",
        "\n",
        "## üîπ Paso 1: Probabilidades previas \"Prior\"\n",
        "\n",
        "Hay 9 casos ‚ÄúYes‚Äù y 5 casos ‚ÄúNo‚Äù.\n",
        "\n",
        "$$\n",
        "P(Yes) = \\frac{9}{14} = 0.642\n",
        "$$\n",
        "\n",
        "$$\n",
        "P(No) = \\frac{5}{14} = 0.358\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "## Paso 2: Clasificaci√≥n de un nuevo ejemplo\n",
        "\n",
        "Queremos clasificar:\n",
        "\n",
        " * Outlook=Sunny, Temperature=Cool, Humidity=High, Wind=Weak *\n",
        "\n",
        "## Paso 3: Probabilidades condicionales\n",
        "\n",
        "| Atributo | Valor | $P(\\text{valor}|\\text{Yes})$ | $P(\\text{valor}|\\text{No})$ |\n",
        "|-----------|--------|----------------------------|----------------------------|\n",
        "| Outlook   | Sunny  | $2/9$ | $3/5$ |\n",
        "| Temperature | Cool | $3/9$ | $1/5$ |\n",
        "| Humidity  | High  | $3/9$ | $4/5$ |\n",
        "| Wind      | Weak  | $6/9$ | $2/5$ |\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "### Para Yes:\n",
        "\n",
        "$$\n",
        "P(Yes|X) \\propto P(Yes)\\,P(Sunny|Yes)\\,P(Cool|Yes)\\,P(High|Yes)\\,P(Weak|Yes)\n",
        "$$\n",
        "\n",
        "$$\n",
        "P(Yes|X) \\propto 0.642 \\times \\frac{2}{9} \\times \\frac{3}{9} \\times \\frac{3}{9} \\times \\frac{6}{9} = 0.0105\n",
        "$$\n",
        "\n",
        "### Para No:\n",
        "\n",
        "$$\n",
        "P(No|X) \\propto P(No)\\,P(Sunny|No)\\,P(Cool|No)\\,P(High|No)\\,P(Weak|No)\n",
        "$$\n",
        "\n",
        "$$\n",
        "P(No|X) \\propto 0.358 \\times \\frac{3}{5} \\times \\frac{1}{5} \\times \\frac{4}{5} \\times \\frac{2}{5} = 0.0138\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "## Paso 4: Decisi√≥n final\n",
        "\n",
        "Como $0.0138 > 0.0105$, el modelo clasifica el ejemplo como:\n",
        "\n",
        "> **PlayTennis = No**\n",
        "\n",
        "---\n",
        "\n",
        "## 7. Interpretaci√≥n\n",
        "\n",
        "El clasificador Naive Bayes no calcula probabilidades absolutas, sino valores **proporcionales**.  \n",
        "El valor mayor determina la clase m√°s probable.  \n",
        "La simplicidad y eficiencia del m√©todo hacen que sea ideal para grandes vol√∫menes de datos, incluso cuando la independencia entre variables no se cumple estrictamente.\n"
      ],
      "metadata": {
        "id": "iH7-dUwxRWhq"
      }
    }
  ]
}
