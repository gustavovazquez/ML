{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gustavovazquez/ML/blob/main/NLP_tf_idf_exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65e58cff",
      "metadata": {
        "id": "65e58cff"
      },
      "source": [
        "### **TF-IDF: Exercises**\n",
        "\n",
        "- Humans ðŸ‘¦ show the most interesting properties of text data\n",
        "- In this notebook, we will explore basic text representations\n",
        "- We will compare raw BoW (Bag of Words) and TF-IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aba334df",
      "metadata": {
        "id": "aba334df"
      },
      "source": [
        "### **About Data: Emotion Detection**\n",
        "\n",
        "Credits: https://www.kaggle.com/datasets/shivamb/emotions-dataset-for-nlp.\n",
        "Ready to download from: https://raw.githubusercontent.com/gustavovazquez/datasets/refs/heads/main/Emotion_classify_Data.csv\n",
        "\n",
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"shivamb/go-emotions-google-emotions-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "The dataset contains text samples labeled with emotions such as:\n",
        "- joy\n",
        "- anger\n",
        "- sadness\n",
        "- fear\n",
        "\n",
        "We will use a sample to better illustrate TF-IDF representation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "313303d3",
      "metadata": {
        "id": "313303d3"
      },
      "outputs": [],
      "source": [
        "#import pandas library\n",
        "\n",
        "\n",
        "#read the dataset with name \"Emotion_classify_Data.csv\" and store it in a variable df\n",
        "\n",
        "\n",
        "#print the shape of dataframe\n",
        "\n",
        "\n",
        "#print top 5 rows\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "935639eb",
      "metadata": {
        "id": "935639eb"
      },
      "outputs": [],
      "source": [
        "#check the distribution of Emotion\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7093c38",
      "metadata": {
        "id": "e7093c38"
      },
      "outputs": [],
      "source": [
        "#Add the new column \"Emotion_num\" which gives a unique number to each of these Emotions\n",
        "#joy --> 0, fear --> 1, anger --> 2\n",
        "\n",
        "\n",
        "#checking the results by printing top 5 rows\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e53f46db",
      "metadata": {
        "id": "e53f46db"
      },
      "source": [
        "### **Modelling without Pre-processing Text data**\n",
        "\n",
        "Letâ€™s start by evaluating the model without preprocessing (weâ€™ll revisit this later)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f1eebca",
      "metadata": {
        "id": "3f1eebca"
      },
      "outputs": [],
      "source": [
        "#import train-test split\n",
        "\n",
        "\n",
        "#Do the 'train-test' splitting with test size of 20%\n",
        "#Note: Give Random state 2022 and also do the stratify sampling\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5ba2bf0",
      "metadata": {
        "id": "a5ba2bf0"
      },
      "outputs": [],
      "source": [
        "#print the shapes of X_train and X_test\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac221dbe",
      "metadata": {
        "id": "ac221dbe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "81b66f60",
      "metadata": {
        "id": "81b66f60"
      },
      "source": [
        "\n",
        "**Attempt 1** :\n",
        "\n",
        "1. using the sklearn pipeline\n",
        "2. training logistic regression\n",
        "3. using BoW representation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d57ed382",
      "metadata": {
        "id": "d57ed382"
      },
      "outputs": [],
      "source": [
        "#import CountVectorizer, RandomForest, pipeline, classification_report from sklearn\n",
        "\n",
        "\n",
        "#1. create a pipeline object\n",
        "\n",
        "\n",
        "\n",
        "#2. fit with X_train and y_train\n",
        "\n",
        "\n",
        "\n",
        "#3. get the predictions for X_test and store it in y_pred\n",
        "\n",
        "\n",
        "\n",
        "#4. print the classfication report\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7b9e947",
      "metadata": {
        "id": "f7b9e947"
      },
      "source": [
        "\n",
        "**Attempt 2** :\n",
        "\n",
        "1. using the sklearn pipeline\n",
        "2. training logistic regression\n",
        "3. using TF-IDF representation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "238461ea",
      "metadata": {
        "id": "238461ea"
      },
      "outputs": [],
      "source": [
        "#import MultinomialNB from sklearn\n",
        "\n",
        "\n",
        "\n",
        "#1. create a pipeline object\n",
        "\n",
        "\n",
        "\n",
        "#2. fit with X_train and y_train\n",
        "\n",
        "\n",
        "\n",
        "#3. get the predictions for X_test and store it in y_pred\n",
        "\n",
        "\n",
        "#4. print the classfication report\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9245c122",
      "metadata": {
        "id": "9245c122"
      },
      "source": [
        "\n",
        "**Attempt 3** :\n",
        "\n",
        "1. using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
        "\n",
        "**Note:**\n",
        "- using CountVectorizer with both unigram and Bigrams.\n",
        "- use **RandomForest** as the classifier.\n",
        "- print the classification report.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1998f9fe",
      "metadata": {
        "id": "1998f9fe"
      },
      "outputs": [],
      "source": [
        "#1. create a pipeline object\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#2. fit with X_train and y_train\n",
        "\n",
        "\n",
        "\n",
        "#3. get the predictions for X_test and store it in y_pred\n",
        "\n",
        "\n",
        "\n",
        "#4. print the classfication report\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b0240ad",
      "metadata": {
        "id": "2b0240ad"
      },
      "source": [
        "\n",
        "**Attempt 4** :\n",
        "\n",
        "1. using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
        "\n",
        "**Note:**\n",
        "- using **TF-IDF vectorizer** for Pre-processing the text.\n",
        "- use **RandomForest** as the classifier.\n",
        "- print the classification report.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "205393cf",
      "metadata": {
        "id": "205393cf"
      },
      "outputs": [],
      "source": [
        "#import TfidfVectorizer from sklearn\n",
        "\n",
        "\n",
        "\n",
        "#1. create a pipeline object\n",
        "\n",
        "\n",
        "\n",
        "#2. fit with X_train and y_train\n",
        "\n",
        "\n",
        "\n",
        "#3. get the predictions for X_test and store it in y_pred\n",
        "\n",
        "\n",
        "#4. print the classfication report\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d31788a",
      "metadata": {
        "id": "4d31788a"
      },
      "source": [
        "<h3>Use text pre-processing to remove stop words, punctuations and apply lemmatization </h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c98cb8fa",
      "metadata": {
        "id": "c98cb8fa"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "\n",
        "# load english language model and create nlp object from it\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "\n",
        "#use this utility function to get the preprocessed text data\n",
        "def preprocess(text):\n",
        "    # remove stop words and lemmatize the text\n",
        "    doc = nlp(text)\n",
        "    filtered_tokens = []\n",
        "    for token in doc:\n",
        "        if token.is_stop or token.is_punct:\n",
        "            continue\n",
        "        filtered_tokens.append(token.lemma_)\n",
        "\n",
        "    return \" \".join(filtered_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd5999a5",
      "metadata": {
        "id": "fd5999a5"
      },
      "outputs": [],
      "source": [
        "# create a new column \"preprocessed_comment\" and use the utility function above to get the clean data\n",
        "# this will take some time, please be patient\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44969a40",
      "metadata": {
        "id": "44969a40"
      },
      "source": [
        "**Build a model with pre processed text**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75e38557",
      "metadata": {
        "id": "75e38557"
      },
      "outputs": [],
      "source": [
        "#Do the 'train-test' splitting with test size of 20% with random state of 2022 and stratify sampling too\n",
        "#Note: Use the preprocessed_Comment\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc8a3a1e",
      "metadata": {
        "id": "bc8a3a1e"
      },
      "source": [
        "**Let's check the scores with our best model till now**\n",
        "- Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90838185",
      "metadata": {
        "id": "90838185"
      },
      "source": [
        "**Attempt1** :\n",
        "\n",
        "1. using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
        "\n",
        "**Note:**\n",
        "- using CountVectorizer with both unigrams and bigrams.\n",
        "- use **RandomForest** as the classifier.\n",
        "- print the classification report.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a226c81",
      "metadata": {
        "id": "9a226c81"
      },
      "outputs": [],
      "source": [
        "#1. create a pipeline object\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#2. fit with X_train and y_train\n",
        "\n",
        "\n",
        "\n",
        "#3. get the predictions for X_test and store it in y_pred\n",
        "\n",
        "\n",
        "\n",
        "#4. print the classfication report\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58d88cf3",
      "metadata": {
        "id": "58d88cf3"
      },
      "source": [
        "\n",
        "**Attempt 2** :\n",
        "\n",
        "1. using the sklearn pipeline module create a classification pipeline to classify the data.\n",
        "\n",
        "**Note:**\n",
        "- using **TF-IDF vectorizer** for pre-processing the text.\n",
        "- use **RandomForest** as the classifier.\n",
        "- print the classification report.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74588bff",
      "metadata": {
        "id": "74588bff"
      },
      "outputs": [],
      "source": [
        "#1. create a pipeline object\n",
        "\n",
        "\n",
        "\n",
        "#2. fit with X_train and y_train\n",
        "\n",
        "\n",
        "\n",
        "#3. get the predictions for X_test and store it in y_pred\n",
        "\n",
        "\n",
        "\n",
        "#4. print the classfication report"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1eba8d1",
      "metadata": {
        "id": "f1eba8d1"
      },
      "source": [
        "## **Please write down Final Observations**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28d630c2",
      "metadata": {
        "id": "28d630c2"
      },
      "source": [
        "## [**Solution**](./tf_idf_exercise_solutions.ipynb)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
