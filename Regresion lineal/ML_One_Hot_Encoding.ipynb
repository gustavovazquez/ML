{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "L8ZUilXpoX8P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# One-Hot Encoding: Concepto, Motivación y Aplicaciones\n",
        "\n",
        "## Introducción\n",
        "\n",
        "En el contexto del aprendizaje automático, los modelos suelen requerir que los datos de entrada estén representados en un formato numérico para ser procesados. Sin embargo, en muchas aplicaciones del mundo real, los datos incluyen variables categóricas, es decir, características cuyos valores pertenecen a un conjunto discreto de categorías. Una de las estrategias más utilizadas para transformar estas variables en un formato adecuado para modelos numéricos es el **one-hot encoding**.\n",
        "\n",
        "## Motivación y Problema de Representación de Variables Categóricas\n",
        "\n",
        "Las variables categóricas pueden clasificarse en **ordinales** y **nominales**:\n",
        "\n",
        "- **Ordinales**: Poseen un orden intrínseco (ej., \"bajo\", \"medio\", \"alto\").\n",
        "- **Nominales**: No poseen un orden natural (ej., \"rojo\", \"verde\", \"azul\").\n",
        "\n",
        "Una forma ingenua de representar variables categóricas es asignarles valores numéricos arbitrarios. Por ejemplo, si tenemos los colores {rojo, verde, azul}, podríamos asignar:\n",
        "\n",
        "- Rojo = 1\n",
        "- Verde = 2\n",
        "- Azul = 3\n",
        "\n",
        "Sin embargo, este enfoque introduce una relación ordinal artificial, ya que el modelo podría interpretar que Azul (>3) es mayor que Verde (>2) y que Verde es mayor que Rojo, lo que no tiene sentido en este contexto.\n",
        "\n",
        "## Definición de One-Hot Encoding\n",
        "\n",
        "El **one-hot encoding** resuelve este problema transformando cada categoría en una representación binaria en la que solo una posición es activada (1) y las demás permanecen en 0. La idea es mapear cada categoría en un vector de dimensión igual al número total de categorías.\n",
        "\n",
        "Siguiendo con el ejemplo de los colores, la representación one-hot sería:\n",
        "\n",
        "- Rojo = [1, 0, 0]\n",
        "- Verde = [0, 1, 0]\n",
        "- Azul = [0, 0, 1]\n",
        "\n",
        "En esta codificación, cada categoría se convierte en un vector independiente, evitando la introducción de relaciones ordinales espurias.\n",
        "\n",
        "## Ventajas de One-Hot Encoding\n",
        "\n",
        "1. **Evita relaciones numéricas espurias**: Como no se asignan valores numéricos directos, el modelo no infiere relaciones inexistentes entre las categorías.\n",
        "2. **Compatibilidad con modelos lineales y basados en distancia**: Modelos como regresión logística o algoritmos basados en distancia (k-NN, SVM) pueden verse afectados si los datos categóricos se representan con valores numéricos arbitrarios.\n",
        "\n",
        "## Limitaciones de One-Hot Encoding\n",
        "\n",
        "A pesar de sus ventajas, esta técnica tiene algunas limitaciones:\n",
        "\n",
        "1. **Explosión de dimensionalidad**: Si la variable categórica tiene un número elevado de categorías (ej., nombres de ciudades o palabras en un corpus de texto), la matriz resultante será muy grande y dispersa.\n",
        "2. **Aumento del costo computacional**: La representación con muchas dimensiones puede aumentar el tiempo de entrenamiento y requerir más memoria.\n",
        "3. **Posible pérdida de información semántica**: No captura relaciones entre categorías. Por ejemplo, en datos de colores, no refleja que \"rojo\" y \"naranja\" son más similares entre sí que \"rojo\" y \"azul\".\n",
        "\n",
        "## Colinealidad en One-Hot Encoding\n",
        "\n",
        "Un problema que surge con el one-hot encoding es la **colinealidad** entre las variables resultantes. Dado que cada fila contiene una única variable con el valor de 1 y el resto son ceros, la suma de todas las columnas siempre será 1. Esto introduce redundancia y puede causar problemas en algunos modelos de regresión lineal y análisis estadísticos.\n",
        "\n",
        "Para evitar la colinealidad, una práctica común es eliminar una de las columnas generadas. Esto no afecta la información contenida en los datos, ya que el valor eliminado puede inferirse a partir de las demás columnas. Por ejemplo, en la codificación one-hot del país de residencia:\n",
        "\n",
        "| País   | EE.UU. | Canadá | México |\n",
        "| ------ | ------ | ------ | ------ |\n",
        "| EE.UU. | 1      | 0      | 0      |\n",
        "| Canadá | 0      | 1      | 0      |\n",
        "| México | 0      | 0      | 1      |\n",
        "\n",
        "Podemos eliminar una columna, por ejemplo \"México\":\n",
        "\n",
        "| País   | EE.UU. | Canadá |\n",
        "| ------ | ------ | ------ |\n",
        "| EE.UU. | 1      | 0      |\n",
        "| Canadá | 0      | 1      |\n",
        "| México | 0      | 0      |\n",
        "\n",
        "Aquí, si ninguna de las columnas \"EE.UU.\" ni \"Canadá\" tiene un valor de 1, se puede inferir que el país es \"México\".\n",
        "\n",
        "OBS: esto es fundamental hacerlo pues en múltiples métodos se debe asegurar que las variables indepentientes no presenten relación entre sí.\n",
        "\n",
        "## Estrategias para Mitigar sus Limitaciones\n",
        "\n",
        "1. **Usar técnicas de reducción de dimensionalidad**: Métodos como PCA (técnica de reducción de la dimensionalidad) pueden ser aplicados sobre la matriz one-hot para reducir su tamaño.\n",
        "2. **Agrupación de categorías**: En variables con muchas categorías, se pueden agrupar en clases más generales antes de aplicar one-hot encoding.\n",
        "3. **Codificación alternativa**: Métodos como **embedding vectors** (aprendidos en modelos de redes neuronales) pueden ser más eficientes para representar categorías con relaciones semánticas.\n",
        "\n",
        "\n",
        "\n",
        "## Ejemplo Conceptual\n",
        "\n",
        "### Ejemplo con Datos Numéricos y Categóricos\n",
        "\n",
        "Consideremos un dataset con dos variables numéricas y una categórica:\n",
        "\n",
        "| ID | Edad | Ingreso | Categoría |\n",
        "| -- | ---- | ------- | --------- |\n",
        "| 1  | 25   | 30000   | A         |\n",
        "| 2  | 45   | 70000   | B         |\n",
        "| 3  | 35   | 50000   | C         |\n",
        "| 4  | 50   | 80000   | A         |\n",
        "| 5  | 28   | 40000   | B         |\n",
        "| 6  | 40   | 60000   | C         |\n",
        "\n",
        "Aplicando one-hot encoding sobre la columna \"Categoría\":\n",
        "\n",
        "| ID | Edad | Ingreso | A | B |\n",
        "| -- | ---- | ------- | - | - |\n",
        "| 1  | 25   | 30000   | 1 | 0 |\n",
        "| 2  | 45   | 70000   | 0 | 1 |\n",
        "| 3  | 35   | 50000   | 0 | 0 |\n",
        "| 4  | 50   | 80000   | 1 | 0 |\n",
        "| 5  | 28   | 40000   | 0 | 1 |\n",
        "| 6  | 40   | 60000   | 0 | 0 |\n",
        "\n",
        "La categoría \"C\" ha sido eliminada para evitar la colinealidad.\n",
        "\n",
        "# Ejemplo usando scikitlearn"
      ],
      "metadata": {
        "id": "ZCkXbbL2oZmg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Crear un pequeño dataset de ejemplo con 10 filas\n",
        "# Incluye dos variables numéricas (Edad, Ingreso) y una categórica (Categoría)\n",
        "df = pd.DataFrame({\n",
        "    \"ID\": range(1, 11),\n",
        "    \"Edad\": [25, 45, 35, 50, 28, 40, 30, 55, 38, 42],\n",
        "    \"Ingreso\": [30000, 70000, 50000, 80000, 40000, 60000, 45000, 85000, 55000, 65000],\n",
        "    \"Categoría\": [\"A\", \"B\", \"C\", \"A\", \"B\", \"C\", \"A\", \"B\", \"C\", \"A\"]\n",
        "})\n",
        "\n",
        "# Mostrar dataframe original\n",
        "print(\"\\nDataFrame Original (dos columnas numéricas y una categórica):\")\n",
        "print(df)\n",
        "\n",
        "\n",
        "# Inicializar el OneHotEncoder de Scikit-Learn\n",
        "# 'drop=\"first' elimina la primera categoría para evitar colinealidad\n",
        "# 'sparse_output=False' devuelve un array en lugar de una matriz sparse\n",
        "\n",
        "# Crear el codificador OneHot, especificando drop='first' para evitar multicolinealidad\n",
        "onehot = OneHotEncoder(sparse_output=False, drop='first')\n",
        "\n",
        "# Ajustar y transformar la columna 'Categoría'\n",
        "categoria_encoded = onehot.fit_transform(df[['Categoría']])\n",
        "\n",
        "# Crear nombres para las nuevas columnas (excluyendo la primera categoría)\n",
        "feature_names = onehot.get_feature_names_out(['Categoría'])\n",
        "\n",
        "# Convertir el array numpy a DataFrame\n",
        "categoria_df = pd.DataFrame(categoria_encoded, columns=feature_names)\n",
        "\n",
        "# Concatenar el DataFrame original con las nuevas columnas codificadas\n",
        "df_final = pd.concat([df.drop('Categoría', axis=1), categoria_df], axis=1)\n",
        "\n",
        "# Mostrar el resultado\n",
        "print(\"\\nDataFrame con codificación OneHot:\")\n",
        "print(df_final)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdtBSsAmshCH",
        "outputId": "0d34ca56-62a9-4036-9edf-0bdf264c0f7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame Original (dos columnas numéricas y una categórica):\n",
            "   ID  Edad  Ingreso Categoría\n",
            "0   1    25    30000         A\n",
            "1   2    45    70000         B\n",
            "2   3    35    50000         C\n",
            "3   4    50    80000         A\n",
            "4   5    28    40000         B\n",
            "5   6    40    60000         C\n",
            "6   7    30    45000         A\n",
            "7   8    55    85000         B\n",
            "8   9    38    55000         C\n",
            "9  10    42    65000         A\n",
            "\n",
            "DataFrame con codificación OneHot:\n",
            "   ID  Edad  Ingreso  Categoría_B  Categoría_C\n",
            "0   1    25    30000          0.0          0.0\n",
            "1   2    45    70000          1.0          0.0\n",
            "2   3    35    50000          0.0          1.0\n",
            "3   4    50    80000          0.0          0.0\n",
            "4   5    28    40000          1.0          0.0\n",
            "5   6    40    60000          0.0          1.0\n",
            "6   7    30    45000          0.0          0.0\n",
            "7   8    55    85000          1.0          0.0\n",
            "8   9    38    55000          0.0          1.0\n",
            "9  10    42    65000          0.0          0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agrupamiento de clases en clases superiores\n",
        "\n",
        "Un ejemplo clásico de una variable categórica con muchas categorías que se puede agrupar en menos es el **código postal** en un estudio de mercado o análisis geográfico.\n",
        "\n",
        "### Caso: Códigos Postales de Montevideo\n",
        "Supongamos que tenemos una base de datos donde los participantes indican su código postal en Montevideo. La variable \"código postal\" puede contener decenas de valores distintos, por ejemplo:\n",
        "\n",
        "11000, 11200, 11300, 11400, 11500, 11600, 11700, 11800, 11900, 12000, 12100, 12200, 12300, 12400, 12500, 12600, 12700, 12800, 12900, 13000, ...\n",
        "\n",
        "Dado que hay demasiados códigos postales, el análisis de los datos puede volverse complicado. Para simplificar, podemos agruparlos en **zonas más generales**, como:\n",
        "\n",
        "1. **Zona Centro**: 11000, 11100, 11200, 11300, 11400\n",
        "2. **Zona Este**: 11500, 11600, 11700, 11800, 11900, 12000\n",
        "3. **Zona Oeste**: 12100, 12200, 12300, 12400\n",
        "4. **Zona Norte**: 12500, 12600, 12700, 12800\n",
        "5. **Zona Sur y Costera**: 12900, 13000 y demás códigos costeros\n",
        "\n",
        "Este proceso de agrupación permite reducir la cantidad de categorías sin perder información relevante para el análisis.\n",
        "\n",
        "**Técnicas para la agrupación:**\n",
        "- **Agrupación geográfica/manual** (como el ejemplo anterior).\n",
        "- **Agrupación por frecuencia**: Si hay muchos códigos postales con pocos casos, agruparlos en \"Otros\".\n",
        "- **Agrupación basada en similitud estadística**: Usando algoritmos como clustering o análisis de componentes principales (PCA) para encontrar grupos naturales.\n",
        "- **Basado en impacto en la variable objetivo**: Si la variable categórica se usa en un modelo predictivo, agrupar códigos con efectos similares sobre la variable objetivo.\n",
        "\n"
      ],
      "metadata": {
        "id": "Bcdr-T3RI-4x"
      }
    }
  ]
}